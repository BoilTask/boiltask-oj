# 通用爬虫规则
User-agent: *
{{/* robotstxt.org - if we are in production, allow access, else deny */ -}}
{{ if hugo.IsProduction -}}
# 允许所有访问
Allow: /
# 禁止访问的路径
Disallow: /*.js$?
Disallow: /*.css$?
Disallow: /*.png$?
Disallow: /*.jpg$?
Disallow: /*.jpeg$?
Disallow: /*.gif$?
Disallow: /*.svg$?
Disallow: /*.ico$?
Disallow: /*.woff$?
Disallow: /*.woff2$?
Disallow: /*.ttf$?
Disallow: /*.eot$?
# 禁止访问的目录
Disallow: /admin/
Disallow: /tmp/
Disallow: /temp/
Disallow: /cache/
# 允许搜索引擎索引特定文件类型
Allow: /*.html$
Allow: /*.htm$
# Sitemap 位置
Sitemap: {{ "/sitemap.xml" | urls.AbsURL }}
{{ else -}}
# 开发环境禁止所有爬虫
Disallow: /
{{ end -}}

# 特定爬虫规则
# Googlebot
User-agent: Googlebot
{{ if hugo.IsProduction -}}
Allow: /
{{ else -}}
Disallow: /
{{ end -}}

# Bingbot
User-agent: Bingbot
{{ if hugo.IsProduction -}}
Allow: /
{{ else -}}
Disallow: /
{{ end -}}

# Baiduspider
User-agent: Baiduspider
{{ if hugo.IsProduction -}}
Allow: /
{{ else -}}
Disallow: /
{{ end -}}

# YandexBot
User-agent: YandexBot
{{ if hugo.IsProduction -}}
Allow: /
{{ else -}}
Disallow: /
{{ end -}}
